version: "3.1"

language: "en"

pipeline:
  # Tokenizer to break the text into words (Whitespace-based)
- name: WhitespaceTokenizer
  case_sensitive: false

  # Regex-based entity features
- name: RegexFeaturizer
  case_sensitive: false

  # Syntactic and lexical features based on token positions
- name: LexicalSyntacticFeaturizer

  # Count Vectors Featurizer for word and n-gram features
- name: CountVectorsFeaturizer
  OOV_token: "[UNK]"
  min_ngram: 1
  max_ngram: 2
  max_features: 10000    # Keep max features at a reasonable level

  # RegexEntityExtractor to capture structured entities (like discipline, industry, size)
- name: RegexEntityExtractor
  use_lookup_tables: true    # Make use of lookup tables defined in your NLU
  lookup_tables:
  - name: discipline
    elements: data/lookup_tables/discipline.txt
  - name: industry
    elements: data/lookup_tables/industry.txt
  - name: size
    elements: data/lookup_tables/size.txt
  - name: duration
    elements: data/lookup_tables/duration.txt
  - name: location
    elements: data/lookup_tables/location.txt

  # DIETClassifier with reduced epochs and optimized settings
- name: DIETClassifier
  epochs: 200    # Reduce epochs to balance between training time and accuracy
  constrain_similarities: true
  entity_recognition: true
  intent_classification: true
  entity_roles: true
  entity_groups: true
  random_seed: 42
  embedding_dimension: 80    # Slightly reduced embedding dimension for faster training
  batch_size: 64    # Moderate batch size for faster iterations
  learning_rate: 0.002    # Keep learning rate constant for good convergence
  entities:
  - discipline
  - industry
  - keywords
  - duration
  - location
  - size

  # Synonym mapping for entities (like size, location types, etc.)
- name: EntitySynonymMapper

  # Fallback classifier for handling ambiguous queries
- name: FallbackClassifier
  threshold: 0.4
  ambiguity_threshold: 0.1

policies:
  # Memoization policy for remembering exact responses
- name: MemoizationPolicy
  max_history: 5    # Reduce history for faster prediction processing

  # Transformer-based TEDPolicy for dialogue management
- name: TEDPolicy
  max_history: 5    # Reduce history length to speed up training
  epochs: 200    # Reduce epochs to shorten training time
  batch_size: 64    # Moderate batch size for faster iterations

  # Rule-based policy for fallback and custom rules
- name: RulePolicy
  core_fallback_threshold: 0.3
  core_fallback_action_name: "action_default_fallback"
  enable_fallback_prediction: true
assistant_id: 20241015-045354-intense-performance
